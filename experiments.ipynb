{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "from visualization.visualize import feature_visualization , heat_map\n",
    "from models.vgg import VggFeatureExtractor\n",
    "from utils.image_utils import preprocess_image\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"data\\content\\wallhaven-9d9g38.jpg\"\n",
    "imge = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(imge)\n",
    "# plt.title('style image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-1: import image and get the features maps of the respective layers [0 , 5 , 10 , 19 , 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VggFeatureExtractor(target_layer=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    img = preprocess_image(image_path)\n",
    "    features = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_visualization(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [0 , 5 , 10 , 19 , 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers = {\n",
    "    layer: VggFeatureExtractor(layer) for layer in layers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict = {'l':2 , 't':5}\n",
    "# for (i, j) in dict.items():\n",
    "#     print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_features = {}\n",
    "img = preprocess_image(image_path)\n",
    "\n",
    "for layer , model in style_layers.items():\n",
    "    with torch.no_grad():\n",
    "        style_features[layer] = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer , feature in style_features.items():\n",
    "    txt = f\"layer : {layer} , dimensions : {feature.shape}\"\n",
    "    print(txt)\n",
    "    # feature_visualization( feature , layer_name = txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-2: Calculate the gram matrix of the feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.rand((1, 3, 2, 2))\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B ,C , H ,W = mat.size()\n",
    "new = mat.reshape( B , C , -1)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = new.transpose(1, 2)\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = torch.bmm(new , trans)\n",
    "mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( B , C , H , W)\n",
    "def _gram_matrix(features):\n",
    "    B , C , H , W = features.size()\n",
    "    features = features.view( B , C , H * W) # ( B , C , M) dim -3\n",
    "    gram = torch.bmm(features , features.transpose(1, 2)) # ( C * M ) , ( M * C)\n",
    "    return gram.div( C * H * W) # (B , C , C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_gram_features = {}\n",
    "\n",
    "for layer , features in style_features.items():\n",
    "    with torch.no_grad():\n",
    "        style_gram_features[layer] = _gram_matrix(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(style_gram_features[layers[0]] , layer_name= f\"Layer : {layers[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_weights = {layer : 1/5 for layer in layers}\n",
    "style_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss( original_gram , style_gram):\n",
    "    return F.mse_loss(original_gram - style_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = torch.randn_like(img, requires_grad=True)\n",
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = generated.squeeze(0).detach().cpu().numpy()\n",
    "img_gen = np.transpose(img_gen, (1, 2, 0))\n",
    "plt.imshow(img_gen)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([generated] ,lr= 0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "\n",
    "def _total_loss(generated , style_gram_features):\n",
    "    generated_style_fetures = \n",
    "\n",
    "\n",
    "def train():\n",
    "    for i in range(iterations):\n",
    "        total_loss = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
